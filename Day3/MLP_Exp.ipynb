{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ccHQemFuZkL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implements a 2 layer perceptron to solve the XOR, a linearly inseperable problem.\n",
        "XOR truth table:\n",
        "\n",
        "        True   |  False\n",
        "        ______________\n",
        "True   | False | True |\n",
        "_____  |_______|______|\n",
        "False  | True  | False|\n",
        "       |_______|______|\n",
        "       \n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# X = <X1, X2, 1 (bias)> here for x1 and x2 generate the truth table for xor gate\n",
        "# Y is labels for xor data\n",
        "x = \n",
        "y = "
      ],
      "metadata": {
        "id": "4raPSxG7um9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, train, hidden, outputs, target, lr=0.01, iters=1000):\n",
        "        self.num_inputs = train.shape[1] \n",
        "        self.hidden = hidden\n",
        "        self.output = outputs  \n",
        "        self.x = train\n",
        "        self.y = target\n",
        "        self.iters = iters\n",
        "        self.lr = lr\n",
        "        \n",
        "        self.w1 =  #uniformly initialize the weights\n",
        "        self.w2 =  #uniformly initialize the weights\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        \"\"\"\n",
        "        Sigmoid activation:\n",
        "        \"\"\"\n",
        "        #write your code here\n",
        "        pass \n",
        "\n",
        "    def classify(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass. \n",
        "        \"\"\"\n",
        "        #write your code here                      \n",
        "        pass\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        for __ in range(self.iters):\n",
        "            z0 =            #(Nx4) (N is number of samples)\n",
        "            a0 =            #(Nx4)\n",
        "            z1 =            #(Nx1)\n",
        "            a1 =            #(Nx1)\n",
        "\n",
        "            # write your code for backpropogation updates for self.w1 and self.w2 \n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "_tjqJif6uqS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = Perceptron(train=x, hidden=4, outputs=1, target=y, lr=0.1, iters=30000)\n",
        "nn.train()\n",
        "out = nn.classify(x)\n",
        "final_out = (out >= 0.5).astype('int').flatten()\n",
        "print(final_out) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jyyRGHuusdr",
        "outputId": "c5007fec-10ef-4a6e-a30a-398c88582807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Cazpsd5uxDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}