{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tZ-KIBqYlBTf"
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "667z_TnclBTl"
      },
      "source": [
        "**Define Data loader & Preprocessing Steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h1ERb8UblBTr"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.path.expanduser('~'), 'Documents', 'OR 610')\n",
        "def read_idx(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
        "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
        "        return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)\n",
        "    \n",
        "def oneHotEncoding(label):\n",
        "    n = np.max(label)+1\n",
        "    v = np.eye(n)[label]\n",
        "    return v.T\n",
        "\n",
        "\n",
        "def imageProcess(data):\n",
        "    data = data/255\n",
        "    data = data.reshape(data.shape[0],data.shape[1]*data.shape[2])\n",
        "    return data.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMl4cEIlBTu"
      },
      "source": [
        "**Define activation functions for forward pass**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MR0UqsElBTw"
      },
      "outputs": [],
      "source": [
        "def softMax(X):\n",
        "    #Write your code here\n",
        "    pass\n",
        "\n",
        "def ReLU(z):\n",
        "  #Write your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "  #Write your code here\n",
        "    pass\n",
        "\n",
        "\n",
        "def tanh(z):\n",
        "  #Write your code here\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn5qtEJvlBTy"
      },
      "source": [
        "**Define Activation functions for backward pass i.e. first derivative of the forward pass activation function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEcQyrNHlBT1"
      },
      "outputs": [],
      "source": [
        "def dReLU(z):\n",
        "  #Write your code here\n",
        "    pass\n",
        "\n",
        "def dSigmoid(z):\n",
        "  #Write your code here\n",
        "    pass\n",
        "\n",
        "def dTanh(z):\n",
        "  #Write your code here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1YeQ_JClBT5"
      },
      "source": [
        "Multi label cross entropy with L2 regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USXYQybAlBT7"
      },
      "source": [
        "**Model Procedures**\n",
        "\n",
        "*Forward Pass:*\n",
        "\n",
        "\\\\(Z_i = W_i \\bullet x^T + b_i \\\\)\n",
        "\n",
        "\\\\(A_i = \\sigma(Z_i)\\\\)\n",
        "\n",
        "\\\\(\\hat{y} = A_i\\\\)\n",
        "\n",
        "where \\\\(\\sigma\\\\) is a nonlinear transformation\n",
        "\n",
        "*Loss Function* with regularization\n",
        "\n",
        "\\\\(L(y,\\hat{y}) = -\\frac{1}{m} \\Sigma_j \\Sigma_i y_i log(\\hat{y_i}) + \\frac{\\lambda}{2*m} * (\n",
        "\\Sigma_w w^2)\\\\)\n",
        "\n",
        "*Back propagation: here we use differental equations and use the chain rule first starting with the cost function and work backwards until we get to weights since we want to learn the weights that give a better fit*\n",
        "\n",
        "\\\\(\\frac{\\delta L}{\\delta w_i} = \\frac{\\delta L}{\\delta \\hat{y}} * \\frac{\\delta \\hat{y}}{\\delta z} * \\frac{\\delta z}{\\delta w_i}\\\\)\n",
        "\n",
        "*Update weights*\n",
        "\n",
        "\\\\(w_i = w_i - \\eta * \\delta w_i - \\frac {(w_i * \\lambda * \\eta)}{m}\\\\)\n",
        "\n",
        "where \\\\(\\eta\\\\) is the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsdofBUilBT_"
      },
      "outputs": [],
      "source": [
        "def crossEntropyR2(y, y_hat, lamda, params):\n",
        "    m = y.shape[1]\n",
        "    cost = -(1/m) * np.sum(y*np.log(y_hat)) + lamda/(2*m) * (np.sum(params['W1']**2) + np.sum(params['W2']**2))\n",
        "    return cost\n",
        "\n",
        "def forward(X,params,activation):\n",
        "\n",
        "    forwardPass = {}\n",
        "    forwardPass['Z1'] = #Write your code here\n",
        "    forwardPass['A1'] = #Write your code here\n",
        "    forwardPass['Z2'] = #Write your code here\n",
        "    forwardPass['A2'] = #Write your code here\n",
        "    return forwardPass\n",
        "\n",
        "\n",
        "def back(X, y,forwardPass, params,dActivation):\n",
        "    m = X.shape[1]\n",
        "    gradient = {}\n",
        "    gradient['dZ2'] = forwardPass['A2'] - y\n",
        "    gradient['dW2'] = #Write your code here\n",
        "    gradient['db2'] = #Write your code here\n",
        "    gradient['dA1'] = #Write your code here\n",
        "    gradient['dZ1'] = #Write your code here\n",
        "    gradient['dW1'] = #Write your code here\n",
        "    gradient['db1'] = #Write your code here\n",
        "    return gradient\n",
        "\n",
        "def updater(params,grad,eta,lamda,m):\n",
        "    updatedParams = {}\n",
        "    updatedParams['W2'] = #Write your code here\n",
        "    updatedParams['b2'] = #Write your code here\n",
        "    updatedParams['W1'] = #Write your code here\n",
        "    updatedParams['b1'] = #Write your code here\n",
        "    return updatedParams\n",
        "\n",
        "def classifer(X, params,activation):\n",
        "    Z1 = np.matmul(params['W1'], X) + params['b1']\n",
        "    A1 = activation(Z1)\n",
        "    Z2 = np.matmul(params['W2'],A1) + params['b2']\n",
        "    A2 = softMax(Z2)\n",
        "    pred = np.argmax(A2, axis=0)\n",
        "    return pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-hl0MXDlBUD"
      },
      "source": [
        "Load Data to memory and define hyper params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu3fK6EqlBUE",
        "outputId": "790e71db-2260-455d-efc8-8d35f942a0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train = imageProcess(read_idx('train-images.idx3-ubyte'))\n",
        "y_train = oneHotEncoding(read_idx('train-labels-idx1-ubyte'))\n",
        "X_test = imageProcess(read_idx('t10k-images-idx3-ubyte'))\n",
        "y_test = read_idx('t10k-labels-idx1-ubyte')\n",
        "\n",
        "#### General Hyperparameters\n",
        "m=100 #batch size\n",
        "n_x = X_train.shape[0]\n",
        "n_h = 100\n",
        "eta = 1\n",
        "lamda = 2\n",
        "np.random.seed(7)\n",
        "epoch = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHxtRD9nlBUJ"
      },
      "source": [
        "Sigmoid - Activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acIGxKmRlBUK",
        "outputId": "44a58c7d-b2a4-4a6b-de5f-2cf38794e348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cost: 1.7302034675508282\n",
            "time to train: 0:00:02.809689\n",
            "Accuracy: 0.6735\n"
          ]
        }
      ],
      "source": [
        "#m = X_train.shape[1]\n",
        "#Initializing weightss\n",
        "sigmoidParams = {'W1': np.random.randn(n_h, n_x)* np.sqrt(1. / n_x),\n",
        "                 'b1': np.zeros((n_h, 1)),\n",
        "                 'W2': np.random.randn(10, n_h)* np.sqrt(1. / n_h),\n",
        "                 'b2': np.zeros((10, 1))\n",
        "                 }\n",
        "\n",
        "start = datetime.now()\n",
        "for i in range(epoch):\n",
        "    #shuffle batch index\n",
        "    idx = np.random.permutation(X_train.shape[1])[:m]\n",
        "    X=X_train[:,idx]\n",
        "    y=y_train[:,idx]\n",
        "    #forward pass\n",
        "    forwardPass = forward(X,sigmoidParams,sigmoid)\n",
        "    #cost\n",
        "    cost = crossEntropyR2(y, forwardPass['A2'], lamda, sigmoidParams)\n",
        "    #back Prop\n",
        "    gradient = back(X, y, forwardPass, sigmoidParams,dSigmoid)\n",
        "    #updating weights\n",
        "    sigmoidParams=updater(sigmoidParams,gradient,eta,lamda,m)\n",
        "\n",
        "difference = datetime.now() - start\n",
        "print(\"Final cost:\", cost)\n",
        "print('time to train:', difference)\n",
        "\n",
        "y_hat = classifer(X_test, sigmoidParams, sigmoid)\n",
        "\n",
        "print('Accuracy:',sum(y_hat==y_test)*1/len(y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA4PdSwslBUM"
      },
      "source": [
        "ReLU Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoEkzxtylBUN",
        "outputId": "436bae74-5ce7-4f9c-85b9-8a25a37dab13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cost: 2.1930798741698205\n",
            "time to train: 0:00:01.821118\n",
            "Accuracy: 0.2032\n"
          ]
        }
      ],
      "source": [
        "#######RELU SECTION ############\n",
        "reluParams = {'W1': np.random.randn(n_h, n_x)* np.sqrt(2. / n_x),\n",
        "                 'b1': np.zeros((n_h, 1)),\n",
        "                 'W2': np.random.randn(10, n_h)* np.sqrt(2. / n_h),\n",
        "                 'b2': np.zeros((10, 1))\n",
        "                 }\n",
        "\n",
        "start = datetime.now()\n",
        "for i in range(epoch):\n",
        "    #shuffle batch index\n",
        "    idx = np.random.permutation(X_train.shape[1])[:m]\n",
        "    X=X_train[:,idx]\n",
        "    y=y_train[:,idx]\n",
        "    #forward pass\n",
        "    forwardPass = forward(X,reluParams,ReLU)\n",
        "    #cost\n",
        "    cost = crossEntropyR2(y, forwardPass['A2'], lamda, reluParams)\n",
        "    #back Prop\n",
        "    gradient = back(X, y, forwardPass, reluParams,dReLU)\n",
        "    #updating weights\n",
        "    reluParams=updater(reluParams,gradient,eta,lamda,m)\n",
        "difference = datetime.now() - start\n",
        "print(\"Final cost:\", cost)\n",
        "print('time to train:', difference)\n",
        "\n",
        "y_hat = classifer(X_test, reluParams, ReLU)\n",
        "\n",
        "\n",
        "print('Accuracy:',sum(y_hat==y_test)*1/len(y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B-InWaQlBUP"
      },
      "source": [
        "Tanh Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9bQPTCRlBUQ",
        "outputId": "45ad5bbf-c0a2-4163-fdd7-48c7fe9c452d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cost: 3.921825705663649\n",
            "time to train: 0:00:02.544482\n",
            "Accuracy: 0.1703\n"
          ]
        }
      ],
      "source": [
        "#######tanh SECTION ############\n",
        "tanhParams = {'W1': np.random.randn(n_h, n_x)* np.sqrt(1. / n_x),\n",
        "                 'b1': np.zeros((n_h, 1)),\n",
        "                 'W2': np.random.randn(10, n_h)* np.sqrt(1. / n_h),\n",
        "                 'b2': np.zeros((10, 1))\n",
        "                 }\n",
        "\n",
        "start = datetime.now()\n",
        "for i in range(epoch):\n",
        "    #shuffle batch index\n",
        "    idx = np.random.permutation(X_train.shape[1])[:m]\n",
        "    X=X_train[:,idx]\n",
        "    y=y_train[:,idx]\n",
        "    #forward pass\n",
        "    forwardPass = forward(X,tanhParams,tanh)\n",
        "    #cost\n",
        "    cost = crossEntropyR2(y, forwardPass['A2'], lamda, tanhParams)\n",
        "    #back Prop\n",
        "    gradient = back(X, y, forwardPass, tanhParams,dTanh)\n",
        "    #updating weights\n",
        "    tanhParams=updater(tanhParams,gradient,eta,lamda,m)\n",
        "difference = datetime.now() - start\n",
        "print(\"Final cost:\", cost)\n",
        "print('time to train:', difference)\n",
        "\n",
        "y_hat = classifer(X_test, tanhParams, tanh)\n",
        "\n",
        "\n",
        "print('Accuracy:',sum(y_hat==y_test)*1/len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg7LpV9mlBUS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "multilayer perceptron_Exp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}